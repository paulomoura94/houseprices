{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Important libraries\n\nimport numpy as np # for linear algebra\nimport pandas as pd # for data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display all the columns of dataframes\npd.pandas.set_option('display.max_columns',None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train dataset import (from kaggle input)\nd_train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\n\n# rows x columns (data shape)\nprint(d_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First 5 records\nd_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Analysis\n   1. Find all **missing** values\n   2. Find all **numerical** variables\n   3. Find the **distribution** of the numerical variables\n   4. Find all the **categorical** variables\n   5. **Cardinality** of categorical variables\n   6. Discover the **outliers**\n   7. Relationship between independent and dependent features (in this case, 'SalePrice' is the dependent one)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Missing Values","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"1) Listing all features (columns) with missing values:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"features_na = [features for features in d_train.columns if d_train[features].isnull().sum() >= 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2) Print the feature name and the percentage of missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in features_na:\n    print(feature, np.round((d_train[feature].isnull().mean())*100, 4),'% missing values.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Finding the relationship between missing values and target variable\nCreates a variable that indicates '1' if the observation was missing or '0' if it wasn't (missing row for each variable/column), and than calculates the median of target variable where the information is missing or present (for the same variable).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in features_na:\n    data = d_train.copy()\n    \n    data[feature] = np.where(data[feature].isnull(),1,0)\n    \n    data.groupby(feature)['SalePrice'].median().plot.bar(color=['blue','orange'])\n    plt.title(feature)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With this relation, we can see that in mostly all of the features, missing values ('1') are related to high 'SalePrice' values - consideting this, we need to replace these values with meaningful data - not only delete it.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Numerical features\nListing and visualizing numerical features (notice that not all of the numerical features are 'quantitative features' - one of them, i.e. is the 'id' of the houses and some of them, i.e. are dates):","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# validade if the feature type is different than 'O' (letter), that means 'object' variable\nnum_features = [feature for feature in d_train.columns if d_train[feature].dtypes != 'O']\n\nprint('Number of numerical variables: ', len(num_features))\n\nd_train[num_features].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Temporal variables (i.e.: datetime variables)\nIn this dataset, we have 4 year (datetime) variables - 'YearBuilt', 'YearRemodAdd','GarageYrBlt', 'YrSold'. We can use a logic to find datetime variables:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"year_feature = [feature for feature in num_features if 'Yr' in feature or 'Year' in feature]\n\nyear_feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exploring these particular features' contents:\nfor feature in year_feature:\n    print(feature, d_train[feature].sort_values().unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Analysing temporal datetime variables (relation between year sold (grouped) and median house price):","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Grouping by 'year sold' feature and considering the median of 'sale price' for each group\n\nd_train.groupby('YrSold')['SalePrice'].median().plot()\nplt.xlabel('Year sold')\nplt.ylabel('Sale price')\nplt.title('Year sold x House prices')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the relation seems to be against intuition. As the years go by, sales prices seem to decrease (maybe this shouldn't be happening). Thereby, we will compare the difference between all other 'years' features with 'SalePrice' - **these differences mean the 'age' of the buildings until it sales, because it computes the differences of each dates**:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in year_feature:\n    if feature !='YrSold':\n        data = d_train.copy()\n        # To capture the difference between year variable and year the house was sold:\n        data[feature] = data['YrSold']- data[feature]\n        \n        plt.scatter(data[feature],data['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('SalePrice')\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Up here, these x-axis show the \"age\" of the buildings. We can see that** **newest building tend to have higher sale prices**.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Discrete variables\nWe'll consider discrete variables those with less than 25 unique values (in this particular case). For that:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"discrete_feature = [feature for feature in num_features if len(d_train[feature].unique())<25 and feature not in year_feature+['Id']]\nprint('Discrete variables count: {}'.format(len(discrete_feature)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(discrete_feature)\nd_train[discrete_feature].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Now, we can find if there is any relation between them (grouped) and the target variable ('SalePrice'):","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in discrete_feature:\n    data=d_train.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.title(feature + ' x Sale price')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Continuous variables\nNow that we have already defined the discrete variables, the logic we're going to use is the opposite of discrete ('not in discrete_feature neither year_feature'):","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"continuous_feature = [feature for feature in num_features if feature not in discrete_feature+year_feature+['Id']]\nprint('Continuous feature count: {}'.format(len(continuous_feature)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We can analyze the continuous values by creating histograms to understand their distribution:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in continuous_feature:\n    data=d_train.copy()\n    data[feature].hist(bins=25)\n    plt.xlabel(feature)\n    plt.ylabel('Count of '+ feature)\n    plt.title(feature+' distribution')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Normalization for continuous variables","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Above, for continuous variables, we can see that most of them are not normaly distributed. We should do that by using **logarithmic transformation**:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in continuous_feature:\n    data=d_train.copy()\n    if 0 in data[feature].unique(): # from now on, we will use this condition and it's because log of zero is undefined, so we apply the function excluding zeros\n        pass\n    else:\n        data[feature] = np.log(data[feature])\n        data['SalePrice'] = np.log(data['SalePrice']) # we should normalize both the feature and the sale price (x and y)\n        plt.scatter(data[feature],data['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('Sale Price')\n        plt.title(feature)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Outliers check","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In order to find out the outliers for **continuous variables**, we can use the boxplot method, in order to better visualize them:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in continuous_feature:\n    data=d_train.copy()\n    if 0 in data[feature].unique():\n        pass\n    else:\n        data[feature] = np.log(data[feature])\n        data.boxplot(column=feature)\n        plt.ylabel(feature)\n        plt.title(feature + ' boxplot (normalized)')\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Categorical features\nNow, it's time to analyze which variables are categorical and compare them:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features=[feature for feature in d_train.columns if data[feature].dtypes=='O']\n# dtypes == 'O' means that the variable is an 'object' type (letter 'O') \ncategorical_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_train[categorical_features].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cardinality\nWe should find out how many categories each and every features have (cardinality of each feature). ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in categorical_features:\n    print('The feature is \"{}\" and there are {} different categories.'.format(feature, len(d_train[feature].unique())))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Finding the relationship between categorical features and independent feature ('SalePrice')\nWe can use **bar plot** and **median values** (considering we have lots of outliers, as seen above) to better visualize the relationship between categorical features and our target variable, 'SalePrice':","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in categorical_features:\n    data=d_train.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.title(feature + ' x SalePrice')\n    plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}